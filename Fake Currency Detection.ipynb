{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2048e59f",
   "metadata": {},
   "source": [
    "To detect fake currency using a Convolutional Neural Network (CNN) in Python, you can follow these steps:\n",
    "\n",
    "Prepare the dataset:\n",
    "\n",
    "Collect a dataset of genuine currency images and fake currency images.\n",
    "Organize the dataset into two separate folders, one for genuine images and one for fake images.\n",
    "Make sure the images are labeled correctly.\n",
    "Set up the environment:\n",
    "\n",
    "Install the required libraries, such as TensorFlow and Keras.\n",
    "Load the dataset:\n",
    "\n",
    "Use an image processing library, such as OpenCV, to read and preprocess the images.\n",
    "Split the dataset into training and testing sets.\n",
    "Build the CNN model:\n",
    "\n",
    "Import the necessary modules from TensorFlow and Keras.\n",
    "Define the architecture of the CNN model, including convolutional layers, pooling layers, and fully connected layers.\n",
    "Compile the model by specifying the loss function, optimizer, and metrics.\n",
    "Train the model:\n",
    "\n",
    "Use the training set to train the CNN model.\n",
    "Specify the number of epochs and batch size.\n",
    "Monitor the training process and adjust hyperparameters if needed.\n",
    "Evaluate the model:\n",
    "\n",
    "Use the testing set to evaluate the performance of the trained model.\n",
    "Calculate metrics such as accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f67280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chine\\anaconda3\\lib\\site-packages\\keras\\backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 5s 230ms/step - loss: 0.6611 - accuracy: 0.8404 - val_loss: 0.5352 - val_accuracy: 0.7801\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 4s 216ms/step - loss: 0.3710 - accuracy: 0.8528 - val_loss: 0.3622 - val_accuracy: 0.8511\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 4s 217ms/step - loss: 0.2887 - accuracy: 0.8901 - val_loss: 0.2964 - val_accuracy: 0.8369\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 4s 215ms/step - loss: 0.1638 - accuracy: 0.9379 - val_loss: 0.4756 - val_accuracy: 0.8369\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 4s 217ms/step - loss: 0.1363 - accuracy: 0.9468 - val_loss: 0.1423 - val_accuracy: 0.9433\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 4s 218ms/step - loss: 0.0949 - accuracy: 0.9628 - val_loss: 0.0824 - val_accuracy: 0.9645\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 4s 216ms/step - loss: 0.0541 - accuracy: 0.9805 - val_loss: 0.3707 - val_accuracy: 0.8582\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 4s 218ms/step - loss: 0.2311 - accuracy: 0.9184 - val_loss: 0.0578 - val_accuracy: 0.9716\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 4s 222ms/step - loss: 0.0583 - accuracy: 0.9770 - val_loss: 0.0204 - val_accuracy: 0.9929\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 4s 232ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Set the path to your dataset\n",
    "dataset_path = 'noteZip/'\n",
    "\n",
    "# Define the classes (labels)\n",
    "classes = ['fake', 'genuine']\n",
    "\n",
    "# Create empty lists to store the images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Load the dataset\n",
    "for cls in classes:\n",
    "    cls_path = os.path.join(dataset_path, cls)\n",
    "    for image_name in os.listdir(cls_path):\n",
    "        image_path = os.path.join(cls_path, image_name)\n",
    "        image = Image.open(image_path)\n",
    "        image = image.resize((128, 128))  # Resize the image if needed\n",
    "        image = np.array(image)\n",
    "        images.append(image)\n",
    "        labels.append(classes.index(cls))\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Define the CNN model architecture\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_data=(test_images, test_labels))\n",
    "\n",
    "model.save('currency_detections.h5') #pre-trained saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "685924ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.67.112:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chine\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3465: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request\n",
    "from werkzeug.utils import secure_filename\n",
    "import os, numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from PIL import Image\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "#Load developed machine learning modea and parameter settings\n",
    "\n",
    "tf.function(\n",
    "    func=None,\n",
    "    input_signature=None,\n",
    "    autograph=True,\n",
    "    jit_compile=None,\n",
    "    reduce_retracing=False,\n",
    "    experimental_implements=None,\n",
    "    experimental_autograph_options=None,\n",
    "    experimental_attributes=None,\n",
    "    experimental_relax_shapes=None,\n",
    "    experimental_compile=None,\n",
    "    experimental_follow_type_hints=None\n",
    ") # tensorflow parameter settings\n",
    "\n",
    "model = tf.keras.models.load_model('currency_detections.h5') #load pre-trained saved model\n",
    "\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload():\n",
    "    if 'image' not in request.files:\n",
    "        return 'No image file provided', 400\n",
    "\n",
    "    image = request.files['image']\n",
    "    if image.filename == '':\n",
    "        return 'No selected image file', 400\n",
    "\n",
    "    # Process the image file as required\n",
    "    filename = secure_filename(image.filename)\n",
    "    filename, extension = os.path.splitext(filename)\n",
    "    count = len('upload/') + 1 # count the numbers of files in the directory\n",
    "    new_name = f'{count}{extension}' # rename image \n",
    "    image.save('uploads/'+new_name) # save the file to directory\n",
    "    \n",
    "    resp = {}\n",
    "    \n",
    "    # Make predictions on new images\n",
    "    # new_image_path = 'noteZip/200_1.jpg'\n",
    "    new_image = Image.open('uploads/'+str(count)+extension)\n",
    "    new_image = new_image.resize((128, 128))\n",
    "    new_image = np.array(new_image) / 255.0\n",
    "    new_image = np.expand_dims(new_image, axis=0)\n",
    "\n",
    "    predictions = model.predict(new_image)\n",
    "    predicted_label = classes[np.argmax(predictions)]\n",
    "\n",
    "    print('Predicted label:', predicted_label)\n",
    "    resp['status']  = predicted_label\n",
    "    return resp['status']\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d9dc16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
